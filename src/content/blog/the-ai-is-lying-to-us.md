---
title: "The AI Will See You Now... And Lie About You"
description: "AI chatbots were supposed to be our smart assistants. Instead, they've become industrial-scale bullshit generators, and it's getting harder to tell what's real."
pubDate: "2025-08-16T14:00:00Z"
heroImage: "@/assets/ai-fake-quotes.webp"
tags: ["ai", "ethics", "opinion", "future"]
---

It finally happened. The AI is now confidently lying about people, and it's not even particularly creative about it. It's like we've armed a pathological liar with the entirety of Wikipedia and told it to "be helpful." The result? A tidal wave of plausible-sounding nonsense that's polluting everything, and we're all caught in the flood.

### The Rise of the Plausible Lie

I stumbled upon a piece in *The Atlantic* that perfectly captures this modern absurdity. Science-fiction author John Scalzi, a man with millions of published words to his name, suddenly found himself being credited with quotes he never uttered. Memes with his face attached to vaguely philosophical, AI-generated lines like "The universe is a joke. A bad one," spread across Facebook. Even the pictures of him were fakes.

This isn't just a case of mistaken identity. It's a synthetic mirage. The author of the *Atlantic* piece, Yair Rosenberg, had it happen to him too. A blog post on a major news site quoted him saying something so mawkish and out of character that it was immediately identifiable—to him, at least—as a fabrication.

And that's the insidious genius of this new problem. The AI-generated lies are *almost* believable. They're "on brand," as one victim put it. They mimic our style, our topics of interest, and then inject a subtle falsehood wrapped in a familiar package. It's a Trojan horse for misinformation, delivered by a machine.

### This Isn't Your Grandpa's "Fake News"

Let's be clear: bogus quotes on the internet are nothing new. But what we're seeing now is different. This is automated, industrial-scale deception. It's the difference between a single person telling a lie and a factory churning out millions of them every hour.

The article highlights how this affects more than just professional writers. A magazine insert distributed by major newspapers quoted a nature guide on a book list that included fake books attributed to real authors. The writer of the insert admitted to using ChatGPT. Had he not been caught, an ordinary person would have had words put in his mouth with no platform to correct the record.

This is the core of the issue: the sheer, overwhelming scale of it all. Chatbots have replaced search engines for millions, becoming the primary source of information. And they are serving up fabrications with unflappable confidence, poisoning the well of public discourse.

### The Junkification of Reality

A German author, Gabriel Yoran, called the degradation of modern tech "The Junkification of the World." He soon found his own work becoming a victim of it, with AI-generated reviews of his book quoting passages that didn't exist.

He raised a chilling point: why should writers "weigh every word and think about every comma" if our work is just going to be fed into a machine that regurgitates a sloppy, error-ridden summary? It's a direct assault on the motivation to create quality work. We're not just dealing with junk products anymore; we're facing the systemic junkification of information, culture, and reality itself.

### So, Who Cleans Up This Mess?

The most infuriating part is the complete diffusion of responsibility. Is the user to blame for trusting the output? Or is it the tech company that built and marketed a powerful lying machine, often for a subscription fee?

The tech giants can hide behind their terms of service, chiding users for being too trusting. Meanwhile, the victims of these "hallucinations" are left to clean up the mess, often with no idea which AI model even generated the lie. As the article aptly puts it, "responsibility is too diffuse for accountability." It's a feature, not a bug.

### The Perfect, Ironic Punchline

As if to prove the entire point of the article in the most meta way possible, it ends with a brilliant, self-referential gut punch. The author describes asking Google's Gemini about AI accountability and getting a powerful quote from OpenAI's CEO, Sam Altman, stating his company should be liable for its model's failures.

The bad news? Altman never said that. Gemini just made it up.

We were promised a future of accessible superintelligence. What we're getting is a future where the most valuable human skill will be discerning reality from an endless sea of automated, artificial bullshit. Good luck to us all.
